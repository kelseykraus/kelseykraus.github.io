<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Research | Kelsey Kraus</title><link>https://kelseykraus.github.io/research.html</link><atom:link href="https://kelseykraus.github.io/research/index.xml" rel="self" type="application/rss+xml"/><description>Research</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 13 Oct 2025 00:00:00 +0000</lastBuildDate><image><url>https://kelseykraus.github.io/media/logo_hu13837894384518818825.png</url><title>Research</title><link>https://kelseykraus.github.io/research.html</link></image><item><title/><link>https://kelseykraus.github.io/research/evaluation.html</link><pubDate>Mon, 13 Oct 2025 00:00:00 +0000</pubDate><guid>https://kelseykraus.github.io/research/evaluation.html</guid><description>&lt;h2 id="human-in-the-loop-ai-evaluation">Human-In-The-Loop AI Evaluation&lt;/h2>
&lt;p>Recently, my research has focused on how to integrate human feedback into training and evaluating large language models, with a focus on improving performance and ensuring alignment with user preferences in real-world contexts. This work demonstrates the limitations of automated metrics in capturing nuance, especially in sensitive tasks like summarization or toxicity detection, and proposes human-centered methodologies that prioritize meaningful evaluation and data curation.&lt;br>&lt;br>A few recent papers and defensive publications can be found here:&lt;/p></description></item><item><title/><link>https://kelseykraus.github.io/research/evaluation_a.html</link><pubDate>Mon, 13 Oct 2025 00:00:00 +0000</pubDate><guid>https://kelseykraus.github.io/research/evaluation_a.html</guid><description>&lt;ul>
&lt;li>2025: &lt;a href="https://arxiv.org/abs/2503.04910">Maximizing Signal in Human-Model Preference Alignment.&lt;/a> &lt;em>Joint work with Margaret Kroll&lt;/em>&lt;/li>
&lt;li>2024: &lt;a href="https://arxiv.org/abs/2410.18218">Optimizing the role of human evaluation in LLM-based spoken document summarization systems.&lt;/a> &lt;em>Joint work with Margaret Kroll&lt;/em>&lt;/li>
&lt;li>2024: &lt;a href="https://www.tdcommons.org/cgi/viewcontent.cgi?article=8197&amp;context=dpubs_series">Lightweight Retrieval Augmented Generation (RAG) Evaluation Pipeline.&lt;/a> &lt;em>Joint work with Margaret Kroll&lt;/em>&lt;/li>
&lt;/ul></description></item><item><title/><link>https://kelseykraus.github.io/research/prosody.html</link><pubDate>Mon, 13 Oct 2025 00:00:00 +0000</pubDate><guid>https://kelseykraus.github.io/research/prosody.html</guid><description>&lt;h2 id="pragmatics--prosody">Pragmatics &amp;amp; Prosody&lt;/h2>
&lt;p>I also work on exploring the connections between formal semantics, pragmatics, and prosody, with a focus on how intonation and discourse particles influence speech acts in empirically grounded ways. A central theme is understanding how these elements, especially in expressions of surprise, function to modify the speech act itself across different languages.&lt;br>&lt;br>You can find some of this work here:&lt;/p></description></item><item><title/><link>https://kelseykraus.github.io/research/prosody_a.html</link><pubDate>Mon, 13 Oct 2025 00:00:00 +0000</pubDate><guid>https://kelseykraus.github.io/research/prosody_a.html</guid><description>&lt;ul>
&lt;li>2019: &lt;a href="https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/596">Intonation and Expectation: English mirative contours and particles.&lt;/a>&lt;/li>
&lt;li>2018: &lt;a href="https://escholarship.org/uc/item/9sz4k1rm">Great Intonations.&lt;/a> &lt;em>Dissertation&lt;/em>&lt;/li>
&lt;/ul></description></item></channel></rss>